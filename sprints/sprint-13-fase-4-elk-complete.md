# Sprint 13 - Fase 4: ELK Stack ‚úÖ COMPLETA

**Data**: 2025-01-16  
**Status**: ‚úÖ COMPLETA  
**Tempo**: ~30 minutos

---

## üéØ Objetivo

Implementar stack ELK (Elasticsearch + Logstash + Kibana) para centralizar logs de todos os servi√ßos.

---

## ‚úÖ Implementado

### 1. Logging Estruturado

#### JSONFormatter
- ‚úÖ Formata logs como JSON
- ‚úÖ Campos padr√£o: timestamp, level, logger, message, module, function, line
- ‚úÖ Campos extras: user_id, correlation_id, audit_action, resource_type, resource_id
- ‚úÖ Suporte a exceptions

**Arquivo**: `src/shared_kernel/infrastructure/logging_config.py`

#### LoggingMiddleware (FastAPI)
- ‚úÖ Gera correlation_id para cada request
- ‚úÖ Loga in√≠cio e fim de requests
- ‚úÖ Loga dura√ß√£o (ms)
- ‚úÖ Loga erros com stack trace
- ‚úÖ Adiciona X-Correlation-ID no response header

**Arquivo**: `src/streaming/infrastructure/web/middleware/logging_middleware.py`

### 2. Integra√ß√£o FastAPI

- ‚úÖ setup_logging() chamado no startup
- ‚úÖ LoggingMiddleware adicionado
- ‚úÖ Logs enviados para Logstash (porta 5000)
- ‚úÖ Fallback para console se Logstash indispon√≠vel

**Arquivo**: `src/streaming/infrastructure/web/main.py`

### 3. Logstash Pipeline

- ‚úÖ Input: TCP porta 5000 (JSON)
- ‚úÖ Filter: Parse timestamp, audit logs, application logs
- ‚úÖ Output: Elasticsearch (√≠ndices por tipo e data)
- ‚úÖ Output: stdout (debug)

**Arquivo**: `monitoring/logstash.conf`

### 4. Docker Compose

- ‚úÖ Elasticsearch 8.11.0 (porta 9200)
- ‚úÖ Logstash 8.11.0 (porta 5000)
- ‚úÖ Kibana 8.11.0 (porta 5601)
- ‚úÖ Volumes persistentes
- ‚úÖ Health checks

**Arquivo**: `docker-compose.dev.yml`

### 5. Testes

#### Testes Unit√°rios (3)
- ‚úÖ test_format_basic_log
- ‚úÖ test_format_with_extra_fields
- ‚úÖ test_format_with_exception

#### Testes de Integra√ß√£o (2)
- ‚úÖ test_setup_logging
- ‚úÖ test_get_logger

#### Smoke Tests (5)
- ‚úÖ test_elasticsearch_health
- ‚úÖ test_logstash_health
- ‚úÖ test_kibana_health
- ‚úÖ test_logs_indexed_in_elasticsearch
- ‚úÖ test_log_search_in_elasticsearch

**Arquivos**:
- `src/shared_kernel/tests/integration/test_logging.py`
- `src/shared_kernel/tests/integration/test_elk_stack.py`

---

## üìä Estat√≠sticas

- **Arquivos criados**: 6
- **Arquivos atualizados**: 1
- **Linhas escritas**: ~450 (Python)
- **Testes**: 10 (3 unit + 2 integration + 5 smoke)
- **Tempo**: ~30 minutos

---

## üöÄ Como Usar

### 1. Iniciar ELK Stack

```bash
# Iniciar todos os servi√ßos
docker-compose -f docker-compose.dev.yml up -d

# Aguardar servi√ßos iniciarem (30s)
timeout /t 30

# Verificar status
docker-compose -f docker-compose.dev.yml ps
```

### 2. Acessar Servi√ßos

- **Elasticsearch**: http://localhost:9200
- **Kibana**: http://localhost:5601
- **Logstash**: localhost:5000 (TCP)

### 3. Verificar Logs no Elasticsearch

```bash
# Listar √≠ndices
curl http://localhost:9200/_cat/indices/gtvision-*

# Buscar logs
curl -X POST http://localhost:9200/gtvision-*/_search -H "Content-Type: application/json" -d "{\"query\":{\"match_all\":{}},\"size\":10}"
```

### 4. Visualizar no Kibana

1. Acesse http://localhost:5601
2. Menu ‚Üí Stack Management ‚Üí Index Patterns
3. Criar pattern: `gtvision-*`
4. Menu ‚Üí Discover
5. Visualizar logs em tempo real

### 5. Executar Testes

```bash
# Testes unit√°rios
poetry run pytest src/shared_kernel/tests/integration/test_logging.py -v

# Smoke tests (requer ELK rodando)
poetry run pytest src/shared_kernel/tests/integration/test_elk_stack.py -v
```

---

## üìã √çndices Elasticsearch

### gtvision-application-YYYY.MM.DD
Logs de aplica√ß√£o (Django + FastAPI)

**Campos**:
- `@timestamp`: Timestamp do log
- `level`: INFO, WARNING, ERROR, CRITICAL
- `logger`: Nome do logger
- `message`: Mensagem do log
- `module`: M√≥dulo Python
- `function`: Fun√ß√£o Python
- `line`: Linha do c√≥digo
- `correlation_id`: ID de correla√ß√£o (requests)
- `user_id`: ID do usu√°rio (se autenticado)

### gtvision-audit-YYYY.MM.DD
Logs de auditoria (LGPD)

**Campos**:
- `@timestamp`: Timestamp da a√ß√£o
- `audit_action`: A√ß√£o executada (CREATE, UPDATE, DELETE, etc)
- `user_id`: ID do usu√°rio
- `resource_type`: Tipo do recurso (camera, stream, etc)
- `resource_id`: ID do recurso
- `correlation_id`: ID de correla√ß√£o

---

## üé® Dashboards Kibana (Sugeridos)

### 1. Application Logs
- Logs por n√≠vel (INFO, ERROR)
- Logs por m√≥dulo
- Top 10 erros
- Timeline de logs

### 2. Audit Trail
- A√ß√µes por usu√°rio
- A√ß√µes por recurso
- Timeline de auditoria
- Alertas de a√ß√µes suspeitas

### 3. Performance
- Dura√ß√£o de requests (p50, p95, p99)
- Requests por endpoint
- Erros por endpoint
- Correlation ID tracking

---

## üîç Queries √öteis

### Buscar logs de erro
```json
{
  "query": {
    "match": {
      "level": "ERROR"
    }
  }
}
```

### Buscar por correlation_id
```json
{
  "query": {
    "term": {
      "correlation_id": "abc-123"
    }
  }
}
```

### Buscar a√ß√µes de auditoria
```json
{
  "query": {
    "bool": {
      "must": [
        {"exists": {"field": "audit_action"}},
        {"term": {"user_id": "user123"}}
      ]
    }
  }
}
```

---

## ‚úÖ Crit√©rios de Sucesso

- [x] Elasticsearch rodando e acess√≠vel
- [x] Logstash recebendo logs na porta 5000
- [x] Kibana acess√≠vel e conectado ao Elasticsearch
- [x] Logs estruturados em JSON
- [x] Correlation ID em todos os requests
- [x] √çndices criados automaticamente
- [x] Logs pesquis√°veis no Elasticsearch
- [x] 10 testes passing (100%)

---

## üéØ Pr√≥ximos Passos

1. ‚úÖ **Fase 4 COMPLETA**
2. üöÄ **Pr√≥ximo**: Fase 5 - HAProxy + Kong (valida√ß√£o)
3. üöÄ **Depois**: Fase 6 - Testes E2E completos

---

## üìù Notas

- Elasticsearch usa 256MB RAM (configur√°vel via ES_JAVA_OPTS)
- Logstash usa 128MB RAM (configur√°vel via LS_JAVA_OPTS)
- Reten√ß√£o de logs: 30 dias (configurar ILM policy)
- Logs s√£o enviados via TCP (mais confi√°vel que UDP)
- Fallback para console se Logstash indispon√≠vel

---

**Status**: ‚úÖ FASE 4 COMPLETA  
**Progresso Sprint 13**: 60% (4/6 fases)  
**Pr√≥xima fase**: Fase 5 - HAProxy + Kong
